
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Tugas 01 : Crawling Berita &#8212; My sample book</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=fa44fd50" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css?v=be8a1c11" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="../_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>

    <script src="../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../_static/doctools.js?v=9a2dae69"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../_static/copybutton.js?v=f281be69"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js?v=4a39c7ea"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js?v=f930bc37"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="../_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'Tugas-PPWA/Tugas01';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="prev" title="Tugas 1 : Webstatis" href="Tugas-1.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-primary-sidebar-checkbox"/>
  <label class="overlay overlay-primary" for="pst-primary-sidebar-checkbox"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          id="pst-secondary-sidebar-checkbox"/>
  <label class="overlay overlay-secondary" for="pst-secondary-sidebar-checkbox"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  
    <header class="bd-header navbar navbar-expand-lg bd-navbar d-print-none">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/PROFIL.png" class="logo__image only-light" alt="My sample book - Home"/>
    <script>document.write(`<img src="../_static/PROFIL.png" class="logo__image only-dark" alt="My sample book - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../intro.html">
                    Welcome to your Jupyter Book
                </a>
            </li>
        </ul>
        <ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="Tugas-1.html">Tugas 1 : Webstatis</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Tugas 01 : <strong>Crawling Berita</strong></a></li>



</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><button class="sidebar-toggle primary-toggle btn btn-sm" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</button></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/Iqbalsuryaa/PPWA/blob/gh-pages/_sources/Tugas-PPWA/Tugas01.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch on Colab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img alt="Colab logo" src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/Iqbalsuryaa/PPWA" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/Iqbalsuryaa/PPWA/issues/new?title=Issue%20on%20page%20%2FTugas-PPWA/Tugas01.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/Tugas-PPWA/Tugas01.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="theme-switch fa-solid fa-sun fa-lg" data-mode="light"></i>
    <i class="theme-switch fa-solid fa-moon fa-lg" data-mode="dark"></i>
    <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"></i>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm pst-navbar-icon search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Tugas 01 : Crawling Berita</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Tugas 01 : <strong>Crawling Berita</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tugas-crawling-berita-online-untuk-mendapatkan-judul-tanggal-dan-isi-dari-sebuah-halaman-website-berita-online">Tugas Crawling Berita Online Untuk Mendapatkan <strong>Judul</strong>, <strong>Tanggal</strong> dan <strong>Isi</strong> dari sebuah halaman website berita online</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#code-program-crawling-berita-online">Code Program <strong>Crawling Berita Online :</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-code-program-crawling-data-berita-online">PENJELASAN CODE PROGRAM <strong>CRAWLING DATA BERITA ONLINE :</strong></a></li>
</ul>

            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="tugas-01-crawling-berita">
<h1>Tugas 01 : <strong>Crawling Berita</strong><a class="headerlink" href="#tugas-01-crawling-berita" title="Link to this heading">#</a></h1>
<p>NAMA : Mohammad Iqbal Surya Ramadhan</p>
<p>NIM  : 210411100002</p>
<p>MATA KULIAH : Pencarian dan Penambangan Web - A</p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="tugas-crawling-berita-online-untuk-mendapatkan-judul-tanggal-dan-isi-dari-sebuah-halaman-website-berita-online">
<h1>Tugas Crawling Berita Online Untuk Mendapatkan <strong>Judul</strong>, <strong>Tanggal</strong> dan <strong>Isi</strong> dari sebuah halaman website berita online<a class="headerlink" href="#tugas-crawling-berita-online-untuk-mendapatkan-judul-tanggal-dan-isi-dari-sebuah-halaman-website-berita-online" title="Link to this heading">#</a></h1>
<p><strong>Pengertian Crawling</strong></p>
<p>Crawling adalah proses otomatisasi yang dilakukan oleh program komputer untuk menjelajahi dan mengumpulkan data dari halaman-halaman web di internet. Proses ini sering kali dilakukan oleh bot yang dikenal sebagai web crawlers atau spiders. Web crawlers ini akan menelusuri (crawl) berbagai situs web, mengakses halaman-halaman yang ada, dan mengunduh atau mengekstraksi informasi yang dibutuhkan untuk kemudian disimpan atau diindeks dalam database.</p>
<p><strong>Crawling website berita adalah</strong> <em>proses otomatis mengumpulkan data dari berbagai situs berita di internet. Proses ini dilakukan oleh program khusus yang disebut crawler atau spider. Crawler ini akan menjelajahi internet, mengunjungi berbagai situs berita, dan mengambil data seperti judul berita, isi berita, tanggal publikasi, dan tautan terkait.</em></p>
<p><strong>Beautiful Soup (Python)</strong></p>
<p><strong>Kelebihan:</strong></p>
<p><em>Mudah digunakan dan memiliki API yang intuitif.</em></p>
<p><em>Cocok untuk proyek-proyek kecil hingga menengah.</em></p>
<p><em>Fleksibel dalam parsing HTML dan XML.</em></p>
<p><strong>Kekurangan:</strong></p>
<p><em>Tidak sekuat Scrapy untuk proyek yang kompleks.</em></p>
<p><em>Tidak memiliki fitur built-in untuk manajemen permintaan seperti Scrapy.</em></p>
<p><strong>Fungsi Crawling</strong></p>
<ol class="arabic simple">
<li><p>Mengindeks Halaman Web:</p></li>
</ol>
<ul class="simple">
<li><p>Crawling adalah langkah pertama dalam proses pengindeksan halaman web oleh mesin pencari. Web crawler akan mengunjungi halaman-halaman web, membaca kontennya, dan menyimpannya ke dalam indeks mesin pencari. Ini memungkinkan mesin pencari untuk menemukan dan menampilkan halaman-halaman tersebut dalam hasil pencarian.</p></li>
</ul>
<ol class="arabic simple" start="2">
<li><p>Pengumpulan Data:</p></li>
</ol>
<ul class="simple">
<li><p>Crawling memungkinkan pengumpulan data dari berbagai situs web untuk keperluan tertentu, seperti analisis bisnis, riset pasar, atau pengembangan model kecerdasan buatan. Dengan crawling, data dari berbagai sumber bisa dikumpulkan secara otomatis tanpa harus melakukannya secara manual.</p></li>
</ul>
<ol class="arabic simple" start="3">
<li><p>Pemantauan Perubahan Konten:</p></li>
</ol>
<ul class="simple">
<li><p>Dengan crawling, perubahan atau pembaruan pada suatu situs web dapat dipantau secara berkala. Ini berguna untuk aplikasi yang memerlukan informasi terbaru, seperti agregator berita, alat pemantau harga, atau layanan notifikasi.</p></li>
</ul>
<ol class="arabic simple" start="4">
<li><p>SEO (Search Engine Optimization):</p></li>
</ol>
<ul class="simple">
<li><p>Bagi pengelola situs web, memahami bagaimana proses crawling bekerja dapat membantu dalam optimasi mesin pencari (SEO). Dengan memastikan bahwa halaman-halaman web mereka mudah di-crawl dan diindeks, mereka bisa meningkatkan kemungkinan situs web mereka muncul di hasil pencarian mesin pencari.</p></li>
</ul>
<p><strong>Teknologi yang Digunakan :</strong></p>
<ul class="simple">
<li><p>Library Pemrograman: Python dengan library seperti BeautifulSoup4, Scrapy, dan Requests adalah pilihan populer karena fleksibel dan memiliki banyak fitur.</p></li>
<li><p>Python dan Scrapy : Scrapy adalah framework open-source di Python yang banyak digunakan untuk crawling data, termasuk berita online. Scrapy memudahkan proses fetching, parsing, dan menyimpan data.</p></li>
<li><p>BeautifulSoup: Library Python ini digunakan untuk mengurai dokumen HTML dan XML, membantu mengekstrak data yang diinginkan dari halaman web.</p></li>
<li><p>Selenium: Selenium digunakan untuk melakukan crawling pada halaman web yang memerlukan interaksi dinamis, seperti login atau scroll.</p></li>
<li><p>API Berita: Beberapa situs berita menyediakan API yang memudahkan akses data mereka tanpa perlu crawling. Ini adalah cara yang lebih legal dan stabil untuk mendapatkan data.</p></li>
<li><p>Perangkat Lunak Khusus: Ada juga perangkat lunak khusus yang dirancang untuk crawling data, seperti Octoparse dan ParseHub.</p></li>
</ul>
<p><strong>Beautiful Soup: Perpustakaan Python untuk Parsing HTML dan XML</strong></p>
<p><strong>Beautiful Soup</strong> <em>adalah sebuah perpustakaan Python yang sangat populer dan mudah digunakan untuk parsing dokumen HTML dan XML. Dengan menggunakan Beautiful Soup, kita dapat mengekstrak data dari halaman web dengan cara yang efisien dan elegan. Bayangkan BeautifulSoup sebagai sebuah parser yang dapat mengubah dokumen HTML atau XML yang berantakan menjadi struktur data yang mudah dipahami oleh Python.</em></p>
<p><strong>Mengapa Menggunakan BeautifulSoup?</strong></p>
<ul class="simple">
<li><p>Sederhana: BeautifulSoup memiliki API yang sangat intuitif dan mudah dipelajari, bahkan bagi pemula.</p></li>
<li><p>Fleksibel: BeautifulSoup dapat digunakan untuk berbagai jenis parsing, mulai dari tugas sederhana hingga yang kompleks.</p></li>
<li><p>Pythonic: BeautifulSoup terintegrasi dengan baik dengan ekosistem Python, sehingga Anda dapat dengan mudah menggabungkan BeautifulSoup dengan perpustakaan Python lainnya.</p></li>
<li><p>Komunitas yang Besar: BeautifulSoup memiliki komunitas yang sangat aktif, sehingga Anda dapat dengan mudah menemukan dokumentasi, tutorial, dan bantuan jika Anda mengalami kesulitan.</p></li>
</ul>
<p><strong>Kegunaan BeautifulSoup</strong></p>
<p><strong>Web Scraping:</strong> <em>Mengambil data dari halaman web untuk berbagai tujuan, seperti analisis sentimen, riset pasar, dan pengembangan aplikasi.</em></p>
<p><strong>Parsing Data:</strong> <em>Mengubah data yang tidak terstruktur menjadi format yang terstruktur.</em></p>
<p><strong>Automasi:</strong> <em>Mengotomatiskan tugas-tugas yang berulang, seperti mengunduh data dari banyak halaman web.</em></p>
<p><strong>Contoh Penggunaan Crawling Data :</strong></p>
<p><strong>E-commerce:</strong> <em>Untuk membandingkan harga produk dari berbagai toko online.</em></p>
<p><strong>Riset Pasar:</strong> <em>Untuk mengumpulkan data tentang tren pasar, opini konsumen, atau perilaku kompetitor.</em></p>
<p><strong>Jurnalisme :</strong> <em>Untuk mengumpulkan data dari berbagai sumber berita untuk membuat laporan yang komprehensif.</em></p>
<p><strong>Pengembangan Produk:</strong> <em>Untuk mengumpulkan data yang dapat digunakan untuk melatih model machine learning dan mengembangkan produk baru.</em></p>
<p><strong>Akademik:</strong> <em>Untuk mengumpulkan data untuk penelitian ilmiah.</em></p>
<p><strong>Tujuan Crawling Berita Online :</strong></p>
<p><strong>Mengumpulkan Informasi :</strong> <em>Tujuan utama crawling berita adalah untuk mengumpulkan informasi terbaru dari berbagai sumber berita. Informasi ini bisa digunakan untuk membuat agregasi berita, analisis sentimen, atau membangun basis data untuk penelitian.</em></p>
<p><strong>Pemantauan Berita:</strong> <em>Crawling dapat digunakan untuk memantau berita secara real-time, membantu perusahaan atau individu untuk tetap up-to-date dengan perkembangan terbaru.</em></p>
<p><strong>Pengindeksan untuk Mesin Pencari:</strong> <em>Beberapa perusahaan melakukan crawling untuk mengindeks konten berita sehingga dapat ditampilkan dalam hasil pencarian.</em></p>
<p><strong>Membangun Agregator Berita:</strong> <em>Data yang dikumpulkan oleh crawler dapat digunakan untuk membuat agregator berita, yaitu platform yang mengumpulkan berita dari berbagai sumber dan menyajikannya dalam satu tempat. Contohnya adalah Google News.</em></p>
<p><strong>Analisis Sentimen:</strong> <em>Dengan mengumpulkan berita dalam jumlah besar, kita dapat menganalisis sentimen publik terhadap suatu topik tertentu. Misalnya, kita dapat mengetahui apakah opini publik terhadap suatu produk baru cenderung positif atau negatif.</em></p>
<p><strong>Riset Jurnalistik:</strong> <em>Wartawan dapat menggunakan data yang dikumpulkan oleh crawler untuk melakukan investigasi atau membuat laporan yang lebih mendalam.</em></p>
<p><strong>Pengembangan AI:</strong> <em>Data berita dapat digunakan untuk melatih model machine learning, misalnya untuk membuat sistem rekomendasi berita atau untuk menghasilkan berita secara otomatis.</em></p>
<p><strong>Manfaat dan Penggunaan Data Hasil Crawling :</strong></p>
<p><strong>Agregasi Berita :</strong> <em>Data yang dikumpulkan dapat digunakan untuk membuat platform agregasi berita yang menyajikan berita dari berbagai sumber.</em></p>
<p><strong>Analisis Sentimen :</strong> <em>Data berita dapat digunakan untuk analisis sentimen, membantu perusahaan memahami opini publik terhadap topik tertentu.</em></p>
<p><strong>Pemantauan Media :</strong> Data dapat dimanfaatkan oleh agensi untuk memantau media dan menyusun laporan tentang tren berita.</p>
<p><strong>Penelitian :</strong> <em>Peneliti dapat menggunakan data hasil crawling untuk studi terkait jurnalisme, media, atau fenomena sosial lainnya.</em></p>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="code-program-crawling-berita-online">
<h1>Code Program <strong>Crawling Berita Online :</strong><a class="headerlink" href="#code-program-crawling-berita-online" title="Link to this heading">#</a></h1>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">time</span>

<span class="c1"># Fungsi untuk mengambil data dari halaman web Detik.com</span>
<span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">kategori</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>
    <span class="n">articles</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s2">&quot;article&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;list-content__item&quot;</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">judul</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>  <span class="c1"># Hentikan jika sudah 10 berita</span>
            <span class="k">return</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">link</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">)[</span><span class="s2">&quot;href&quot;</span><span class="p">]</span>
            <span class="n">article_response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
            <span class="n">article_response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="k">except</span> <span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request for article failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">article_soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">article_response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>
        <span class="n">title_element</span> <span class="o">=</span> <span class="n">article_soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;h1&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;detail__title&quot;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">title_element</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">title_element</span> <span class="k">else</span> <span class="s2">&quot;Title Not Found&quot;</span>
        <span class="n">date_element</span> <span class="o">=</span> <span class="n">article_soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;div&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;detail__date&quot;</span><span class="p">)</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">date_element</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">date_element</span> <span class="k">else</span> <span class="s2">&quot;Date Not Found&quot;</span>
        <span class="n">content_element</span> <span class="o">=</span> <span class="n">article_soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;div&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;detail__body-text&quot;</span><span class="p">)</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">content_element</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">content_element</span> <span class="k">else</span> <span class="s2">&quot;Content Not Found&quot;</span>

        <span class="n">judul</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">tanggal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">date</span><span class="p">)</span>
        <span class="n">isi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Menambahkan jeda waktu 1 detik antara permintaan artikel</span>

<span class="c1"># Membuat list url dan kategori yang akan di-crawl</span>
<span class="n">base_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;https://oto.detik.com/indeks&quot;</span><span class="p">]</span>
<span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Otomotif&quot;</span><span class="p">]</span>

<span class="c1"># Inisialisasi list untuk menyimpan data</span>
<span class="n">judul</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">tanggal</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">isi</span> <span class="o">=</span> <span class="p">[]</span>

<span class="c1"># Melakukan iterasi untuk setiap url dan kategori</span>
<span class="k">for</span> <span class="n">base_url</span><span class="p">,</span> <span class="n">category</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">base_urls</span><span class="p">,</span> <span class="n">categories</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>  <span class="c1"># Looping untuk beralih halaman</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">judul</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>  <span class="c1"># Hentikan jika sudah 10 berita</span>
            <span class="k">break</span>

        <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_url</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">get_data</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Menambahkan jeda waktu 2 detik antara permintaan halaman</span>

<span class="c1"># Membuat dataframe dari list data</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;judul&quot;</span><span class="p">:</span> <span class="n">judul</span><span class="p">,</span>
    <span class="s2">&quot;tanggal&quot;</span><span class="p">:</span> <span class="n">tanggal</span><span class="p">,</span>
    <span class="s2">&quot;isi&quot;</span><span class="p">:</span> <span class="n">isi</span>
<span class="p">})</span>

<span class="c1"># Menyimpan dataframe ke file CSV</span>
<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;Crawl-berita-Otomotif.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Komunitas Moge HOG Indo Jakarta Chapter Tuntaskan Touring ke Bali
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Hyundai Venue Siap Tantang Rocky-Raize, Segini Nilai Jualnya
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Ini Cara Komunitas Toyota Yaris Rayakan Ulang Tahun Ke-18
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Perusahaan Induk KTM PHK Ratusan Karyawan Gara-gara Penjualan Anjlok
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Aktivitas Produksi Mobil di Pabrik GM Ekuador yang Bakal Tutup Selamanya
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Penjualan Sepeda Motor Tetap &#39;Aman&#39; Berkat Hal Ini
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Potret Mobil Baru Fajar Alfian, Hadiah untuk Orang Tua
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Pemerintah Diminta Tutup Gojek-Grab, Nasib Ojol Bagaimana?
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Sialnya Nasib Luca Marini: Balapan Sendirian di Belakang, Nyaris Di-overlap Marquez
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Kesederhanaan Paus Fransiskus: Dulu Tolak Lamborghini, Kini Naik Innova Zenix
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;Crawl-berita-Otomotif.csv&quot;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html">
  <div id="df-392fe064-c3d5-4f34-9897-967b029c015c" class="colab-df-container">
    <div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>judul</th>
      <th>tanggal</th>
      <th>isi</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>Komunitas Moge HOG Indo Jakarta Chapter Tuntas...</td>
      <td>Selasa, 03 Sep 2024 20:38 WIB</td>
      <td>Jakarta - Komunitas motor gede (moge) Harley-D...</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Hyundai Venue Siap Tantang Rocky-Raize, Segini...</td>
      <td>Selasa, 03 Sep 2024 20:01 WIB</td>
      <td>Jakarta - Hyundai telah mendaftarkan SUV compa...</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Ini Cara Komunitas Toyota Yaris Rayakan Ulang ...</td>
      <td>Selasa, 03 Sep 2024 19:43 WIB</td>
      <td>Jakarta - Toyota Yaris Club Indonesia (TYCI) m...</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Perusahaan Induk KTM PHK Ratusan Karyawan Gara...</td>
      <td>Selasa, 03 Sep 2024 19:07 WIB</td>
      <td>Jakarta - Perusahaan induk KTM, Pierer Mobilit...</td>
    </tr>
    <tr>
      <th>4</th>
      <td>Aktivitas Produksi Mobil di Pabrik GM Ekuador ...</td>
      <td>Selasa, 03 Sep 2024 18:30 WIB</td>
      <td>Ekuador - Pabrik General Motors GM.N di Ekuado...</td>
    </tr>
    <tr>
      <th>5</th>
      <td>Penjualan Sepeda Motor Tetap 'Aman' Berkat Hal...</td>
      <td>Selasa, 03 Sep 2024 18:04 WIB</td>
      <td>Jakarta - Angka penjualan motor bisa dikatakan...</td>
    </tr>
    <tr>
      <th>6</th>
      <td>Potret Mobil Baru Fajar Alfian, Hadiah untuk O...</td>
      <td>Selasa, 03 Sep 2024 17:43 WIB</td>
      <td>Jakarta - Fajar Alfian, pebulu tangkis nasiona...</td>
    </tr>
    <tr>
      <th>7</th>
      <td>Pemerintah Diminta Tutup Gojek-Grab, Nasib Ojo...</td>
      <td>Selasa, 03 Sep 2024 17:13 WIB</td>
      <td>Jakarta - Garda Indonesia tak setuju dengan de...</td>
    </tr>
    <tr>
      <th>8</th>
      <td>Sialnya Nasib Luca Marini: Balapan Sendirian d...</td>
      <td>Selasa, 03 Sep 2024 16:45 WIB</td>
      <td>Jakarta - Nasib sial menimpa Luca Marini pada ...</td>
    </tr>
    <tr>
      <th>9</th>
      <td>Kesederhanaan Paus Fransiskus: Dulu Tolak Lamb...</td>
      <td>Selasa, 03 Sep 2024 16:13 WIB</td>
      <td>Jakarta - Paus Fransiskus, pemimpin negara Vat...</td>
    </tr>
  </tbody>
</table>
</div>
    <div class="colab-df-buttons">
      
  <div class="colab-df-container">
    <button class="colab-df-convert" onclick="convertToInteractive('df-392fe064-c3d5-4f34-9897-967b029c015c')"
            title="Convert this dataframe to an interactive table."
            style="display:none;">
      
  <svg xmlns="http://www.w3.org/2000/svg" height="24px" viewBox="0 -960 960 960">
    <path d="M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z"/>
  </svg>
    </button>
    
  <style>
    .colab-df-container {
      display:flex;
      gap: 12px;
    }

    .colab-df-convert {
      background-color: #E8F0FE;
      border: none;
      border-radius: 50%;
      cursor: pointer;
      display: none;
      fill: #1967D2;
      height: 32px;
      padding: 0 0 0 0;
      width: 32px;
    }

    .colab-df-convert:hover {
      background-color: #E2EBFA;
      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);
      fill: #174EA6;
    }

    .colab-df-buttons div {
      margin-bottom: 4px;
    }

    [theme=dark] .colab-df-convert {
      background-color: #3B4455;
      fill: #D2E3FC;
    }

    [theme=dark] .colab-df-convert:hover {
      background-color: #434B5C;
      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);
      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));
      fill: #FFFFFF;
    }
  </style>

    <script>
      const buttonEl =
        document.querySelector('#df-392fe064-c3d5-4f34-9897-967b029c015c button.colab-df-convert');
      buttonEl.style.display =
        google.colab.kernel.accessAllowed ? 'block' : 'none';

      async function convertToInteractive(key) {
        const element = document.querySelector('#df-392fe064-c3d5-4f34-9897-967b029c015c');
        const dataTable =
          await google.colab.kernel.invokeFunction('convertToInteractive',
                                                    [key], {});
        if (!dataTable) return;

        const docLinkHtml = 'Like what you see? Visit the ' +
          '<a target="_blank" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'
          + ' to learn more about interactive tables.';
        element.innerHTML = '';
        dataTable['output_type'] = 'display_data';
        await google.colab.output.renderOutput(dataTable, element);
        const docLink = document.createElement('div');
        docLink.innerHTML = docLinkHtml;
        element.appendChild(docLink);
      }
    </script>
  </div>
  
    </div>
  </div>
  </div></div>
</div>
</section>
<section class="tex2jax_ignore mathjax_ignore" id="penjelasan-code-program-crawling-data-berita-online">
<h1>PENJELASAN CODE PROGRAM <strong>CRAWLING DATA BERITA ONLINE :</strong><a class="headerlink" href="#penjelasan-code-program-crawling-data-berita-online" title="Link to this heading">#</a></h1>
<p><strong>Import Libraries</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">from</span> <span class="nn">bs4</span> <span class="kn">import</span> <span class="n">BeautifulSoup</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">time</span>

</pre></div>
</div>
<p><strong>requests :</strong> <em>Library ini digunakan untuk mengirimkan HTTP request ke situs web dan mendapatkan respons dalam bentuk HTML.</em></p>
<p><strong>BeautifulSoup :</strong> <em>Merupakan bagian dari library bs4 yang digunakan untuk mengurai dan mengekstrak data dari dokumen HTML atau XML dengan cara yang mudah dibaca.</em></p>
<p><strong>pandas :</strong> <em>Library ini digunakan untuk manipulasi dan analisis data. Di sini, kita menggunakannya untuk membuat DataFrame dan menyimpan data dalam format CSV.</em></p>
<p><strong>time :</strong> <em>Library standar Python yang digunakan untuk mengatur jeda waktu (delay) antara operasi tertentu.</em></p>
<p><strong>Fungsi get_data</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_data</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">kategori</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">)</span>
        <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
    <span class="k">except</span> <span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
        <span class="k">return</span>

    <span class="n">soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>
    <span class="n">articles</span> <span class="o">=</span> <span class="n">soup</span><span class="o">.</span><span class="n">find_all</span><span class="p">(</span><span class="s2">&quot;article&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;list-content__item&quot;</span><span class="p">)</span>

</pre></div>
</div>
<p><strong>def get_data(url, kategori):</strong> <em>Mendefinisikan sebuah fungsi bernama get_data yang menerima dua parameter : url (alamat halaman web yang akan di-crawl) dan kategori (kategori berita, misalnya ‘Otomotif’).</em></p>
<p><strong>try: response = requests.get(url):</strong> <em>Mengirimkan request HTTP GET ke url yang diberikan untuk mendapatkan halaman web.</em></p>
<p><strong>response.raise_for_status():</strong> <em>Memeriksa apakah permintaan HTTP berhasil (status kode 200). Jika gagal, exception akan di-raise.</em></p>
<p><strong>except requests.exceptions.RequestException as e:</strong> <em>Menangkap semua jenis error yang terkait dengan HTTP request, dan menampilkan pesan error jika ada.</em></p>
<p><strong>soup = BeautifulSoup(response.content, “html.parser”):</strong> <em>Mengurai konten HTML dari respons web menggunakan BeautifulSoup untuk mempermudah ekstraksi data.</em></p>
<p><strong>articles = soup.find_all(“article”, class_=”list-content__item”):</strong> <em>Mencari semua elemen article dengan class list-content__item, yang kemungkinan besar merupakan elemen HTML yang berisi berita.</em></p>
<p><strong>Ekstraksi Data dari Setiap Artikel</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span>    <span class="k">for</span> <span class="n">article</span> <span class="ow">in</span> <span class="n">articles</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">judul</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>  <span class="c1"># Hentikan jika sudah 10 berita</span>
            <span class="k">return</span>

        <span class="k">try</span><span class="p">:</span>
            <span class="n">link</span> <span class="o">=</span> <span class="n">article</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;a&quot;</span><span class="p">)[</span><span class="s2">&quot;href&quot;</span><span class="p">]</span>
            <span class="n">article_response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">link</span><span class="p">)</span>
            <span class="n">article_response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>
        <span class="k">except</span> <span class="p">(</span><span class="n">requests</span><span class="o">.</span><span class="n">exceptions</span><span class="o">.</span><span class="n">RequestException</span><span class="p">,</span> <span class="ne">TypeError</span><span class="p">)</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
            <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request for article failed: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
            <span class="k">continue</span>

        <span class="n">article_soup</span> <span class="o">=</span> <span class="n">BeautifulSoup</span><span class="p">(</span><span class="n">article_response</span><span class="o">.</span><span class="n">content</span><span class="p">,</span> <span class="s2">&quot;html.parser&quot;</span><span class="p">)</span>
        <span class="n">title_element</span> <span class="o">=</span> <span class="n">article_soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;h1&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;detail__title&quot;</span><span class="p">)</span>
        <span class="n">title</span> <span class="o">=</span> <span class="n">title_element</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">title_element</span> <span class="k">else</span> <span class="s2">&quot;Title Not Found&quot;</span>
        <span class="n">date_element</span> <span class="o">=</span> <span class="n">article_soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;div&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;detail__date&quot;</span><span class="p">)</span>
        <span class="n">date</span> <span class="o">=</span> <span class="n">date_element</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">date_element</span> <span class="k">else</span> <span class="s2">&quot;Date Not Found&quot;</span>
        <span class="n">content_element</span> <span class="o">=</span> <span class="n">article_soup</span><span class="o">.</span><span class="n">find</span><span class="p">(</span><span class="s2">&quot;div&quot;</span><span class="p">,</span> <span class="n">class_</span><span class="o">=</span><span class="s2">&quot;detail__body-text&quot;</span><span class="p">)</span>
        <span class="n">content</span> <span class="o">=</span> <span class="n">content_element</span><span class="o">.</span><span class="n">text</span><span class="o">.</span><span class="n">strip</span><span class="p">()</span> <span class="k">if</span> <span class="n">content_element</span> <span class="k">else</span> <span class="s2">&quot;Content Not Found&quot;</span>

        <span class="n">judul</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">tanggal</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">date</span><span class="p">)</span>
        <span class="n">isi</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">content</span><span class="p">)</span>

        <span class="nb">print</span><span class="p">(</span><span class="n">title</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>  <span class="c1"># Menambahkan jeda waktu 1 detik antara permintaan artikel</span>

</pre></div>
</div>
<p><strong>for article in articles :</strong> <em>Iterasi melalui setiap elemen article yang ditemukan di halaman.</em></p>
<p><strong>if len(judul) &gt;= 10 :</strong> <em>Mengecek apakah jumlah berita yang di-crawl sudah mencapai 10. Jika ya, fungsi akan berhenti (return).</em></p>
<p><strong>link = article.find(“a”)[“href”] :</strong> <em>Menemukan elemen a (link) di dalam artikel dan mengambil atribut href yang merupakan URL dari artikel tersebut.</em></p>
<p><strong>article_response = requests.get(link) :</strong> <em>Mengirimkan request HTTP GET ke URL artikel untuk mendapatkan konten halaman berita.</em></p>
<p><strong>article_soup = BeautifulSoup(article_response.content, “html.parser”)</strong> <em>Mengurai konten HTML dari halaman artikel.</em></p>
<p><strong>title_element = article_soup.find(“h1”, class_=”detail__title”) :</strong> <em>Mencari elemen h1 yang memiliki class detail__title untuk mendapatkan judul berita.</em></p>
<p><strong>title = title_element.text.strip() if title_element else “Title Not Found” :</strong> <em>Jika elemen judul ditemukan, teksnya diekstrak dan dihapus spasi berlebih; jika tidak, akan menggunakan nilai default “Title Not Found”.</em></p>
<p><strong>date_element = article_soup.find(“div”, class_=”detail__date”) :</strong> <em>Mencari elemen div yang memiliki class detail__date untuk mendapatkan tanggal publikasi berita.</em></p>
<p><strong>content_element = article_soup.find(“div”, class_=”detail__body-text”) :</strong> <em>Mencari elemen div yang memiliki class detail__body-text untuk mendapatkan isi berita.</em></p>
<p><strong>judul.append(title), tanggal.append(date), isi.append(content) :</strong> <em>Menambahkan judul, tanggal, dan isi berita ke dalam list yang sesuai.</em></p>
<p><strong>time.sleep(1) :</strong> <em>Menambahkan jeda waktu 1 detik antara permintaan untuk menghindari terlalu banyak permintaan dalam waktu singkat (rate-limiting).</em></p>
<p><strong>Inisialisasi URL dan Kategori</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">base_urls</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;https://oto.detik.com/indeks&quot;</span><span class="p">]</span>
<span class="n">categories</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;Otomotif&quot;</span><span class="p">]</span>

</pre></div>
</div>
<p><strong>base_urls :</strong> <em>List yang berisi URL dasar dari halaman indeks berita untuk kategori tertentu (dalam hal ini, Otomotif).</em></p>
<p><strong>categories :</strong> <em>List yang berisi kategori berita yang akan di-crawl.</em></p>
<p><strong>Inisialisasi List untuk Menyimpan Data</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">judul</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">tanggal</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">isi</span> <span class="o">=</span> <span class="p">[]</span>

</pre></div>
</div>
<p><strong>judul, tanggal, isi:</strong> <em>List kosong yang akan digunakan untuk menyimpan data berita yang di-crawl, seperti judul, tanggal, dan isi berita.</em></p>
<p><strong>Iterasi Melalui Halaman dan Kategori</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">base_url</span><span class="p">,</span> <span class="n">category</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">base_urls</span><span class="p">,</span> <span class="n">categories</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">page</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">):</span>  <span class="c1"># Looping untuk beralih halaman</span>
        <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">judul</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="mi">10</span><span class="p">:</span>  <span class="c1"># Hentikan jika sudah 10 berita</span>
            <span class="k">break</span>

        <span class="n">url</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">base_url</span><span class="si">}</span><span class="s2">/</span><span class="si">{</span><span class="n">page</span><span class="si">}</span><span class="s2">&quot;</span>
        <span class="n">get_data</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">category</span><span class="p">)</span>
        <span class="n">time</span><span class="o">.</span><span class="n">sleep</span><span class="p">(</span><span class="mi">2</span><span class="p">)</span>  <span class="c1"># Menambahkan jeda waktu 2 detik antara permintaan halaman</span>

</pre></div>
</div>
<p><strong>for base_url, category in zip(base_urls, categories) :</strong> <em>Iterasi melalui setiap pasangan base_url dan category (meskipun dalam contoh ini hanya ada satu kategori dan URL).</em></p>
<p><strong>for page in range(1, 4) :</strong> <em>Looping untuk halaman 1 hingga 3, untuk meng-crawl beberapa halaman indeks berita.</em></p>
<p><strong>if len(judul) &gt;= 10 :</strong> <em>Mengecek apakah sudah ada 10 berita yang di-crawl. Jika ya, iterasi dihentikan (break).</em></p>
<p><strong>url = f”{base_url}/{page}” :</strong> <em>Menggabungkan base_url dengan nomor halaman untuk membuat URL yang lengkap.</em></p>
<p><strong>get_data(url, category) :</strong> <em>Memanggil fungsi get_data untuk meng-crawl data dari halaman tersebut.</em></p>
<p><strong>time.sleep(2) :</strong> <em>Menambahkan jeda waktu 2 detik antara permintaan halaman untuk mencegah rate-limiting.</em></p>
<p><strong>Membuat DataFrame dan Menyimpan ke CSV</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">({</span>
    <span class="s2">&quot;judul&quot;</span><span class="p">:</span> <span class="n">judul</span><span class="p">,</span>
    <span class="s2">&quot;tanggal&quot;</span><span class="p">:</span> <span class="n">tanggal</span><span class="p">,</span>
    <span class="s2">&quot;isi&quot;</span><span class="p">:</span> <span class="n">isi</span>
<span class="p">})</span>

<span class="n">df</span><span class="o">.</span><span class="n">to_csv</span><span class="p">(</span><span class="s2">&quot;Crawl-berita-Otomotif.csv&quot;</span><span class="p">,</span> <span class="n">index</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

</pre></div>
</div>
<p><strong>df = pd.DataFrame({“judul”: judul, “tanggal”: tanggal, “isi”: isi}) :</strong> <em>Membuat DataFrame dari list judul, tanggal, dan isi.</em></p>
<p><strong>df.to_csv(“Crawl-berita-Otomotif.csv”, index=False) :</strong> <em>Menyimpan DataFrame ke dalam file CSV dengan nama Crawl-berita-Otomotif.csv.</em></p>
<p><em>Parameter index=False digunakan untuk tidak menyimpan indeks DataFrame dalam file CSV.</em></p>
<p><strong>Membaca dan Menampilkan Data dari CSV</strong></p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">=</span><span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s2">&quot;Crawl-berita-Otomotif.csv&quot;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
<p><strong>df = pd.read_csv(“Crawl-berita-Otomotif.csv”) :</strong> <em>Membaca kembali data dari file CSV ke dalam DataFrame df.</em></p>
<p><strong>df :</strong> <em>Menampilkan isi DataFrame df untuk melihat data yang telah di-crawl dan disimpan.</em></p>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./Tugas-PPWA"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="Tugas-1.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Tugas 1 : Webstatis</p>
      </div>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#">Tugas 01 : <strong>Crawling Berita</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#tugas-crawling-berita-online-untuk-mendapatkan-judul-tanggal-dan-isi-dari-sebuah-halaman-website-berita-online">Tugas Crawling Berita Online Untuk Mendapatkan <strong>Judul</strong>, <strong>Tanggal</strong> dan <strong>Isi</strong> dari sebuah halaman website berita online</a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#code-program-crawling-berita-online">Code Program <strong>Crawling Berita Online :</strong></a></li>
<li class="toc-h1 nav-item toc-entry"><a class="reference internal nav-link" href="#penjelasan-code-program-crawling-data-berita-online">PENJELASAN CODE PROGRAM <strong>CRAWLING DATA BERITA ONLINE :</strong></a></li>
</ul>

  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By 210411100002 - Mohammad Iqbal Surya Ramadhan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>