{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"https://github.com/Iqbalsuryaa/PPWA/blob/gh-pages/_sources/Tugas-PPWA/Tugas01.ipynb","timestamp":1726728676733}],"authorship_tag":"ABX9TyOoTjLU5uKvB6KZj3hqFseC"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Tugas 01 : **Crawling Berita**"],"metadata":{"id":"-FH6Dz3KgbDb"}},{"cell_type":"markdown","source":["NAMA : Mohammad Iqbal Surya Ramadhan\n","\n","NIM  : 210411100002\n","\n","MATA KULIAH : Pencarian dan Penambangan Web - A"],"metadata":{"id":"phHx6bi6AffJ"}},{"cell_type":"markdown","source":["# Tugas Crawling Berita Online Untuk Mendapatkan **Judul**, **Tanggal**, **Isi** dan **Kategori Berita** dari sebuah halaman website berita online"],"metadata":{"id":"KnNE76GYwjK2"}},{"cell_type":"markdown","source":["**Pengertian Crawling**\n","\n","\n","Crawling adalah proses otomatisasi yang dilakukan oleh program komputer untuk menjelajahi dan mengumpulkan data dari halaman-halaman web di internet. Proses ini sering kali dilakukan oleh bot yang dikenal sebagai web crawlers atau spiders. Web crawlers ini akan menelusuri (crawl) berbagai situs web, mengakses halaman-halaman yang ada, dan mengunduh atau mengekstraksi informasi yang dibutuhkan untuk kemudian disimpan atau diindeks dalam database.\n","\n","**Crawling website berita adalah** *proses otomatis mengumpulkan data dari berbagai situs berita di internet. Proses ini dilakukan oleh program khusus yang disebut crawler atau spider. Crawler ini akan menjelajahi internet, mengunjungi berbagai situs berita, dan mengambil data seperti judul berita, isi berita, tanggal publikasi, dan tautan terkait.*"],"metadata":{"id":"q0XAJBRjeE0X"}},{"cell_type":"markdown","source":["**Penjelasan Data**\n","\n","*Data yang diambil berasal dari Website DetikOto, yang merupakan bagian dari portal berita Detik.com, berfokus pada topik otomotif, termasuk ulasan kendaraan, berita terbaru, tips perawatan, dan tren otomotif terkini.*\n","\n","*Data diambil menggunakan metode web crawling atau scraping untuk pengumpulan data dengan mengarahkan crawler ke https://oto.detik.com/indeks dan mengumpulkan data terkait otomotif.*\n","\n","**contoh data :**\n","- judul : *Komunitas Moge HOG Indo Jakarta Chapter Tuntaskan Touring ke Bali*\n","\n","- tanggal : *Selasa, 03 Sep 2024 20:38 WIB*\n","\n","- isi/deskripsi : *Jakarta - Komunitas motor gede (moge) Harley-Davidson Owners Group (H.O.G.) Indo Jakarta Chapter telah menuntaskan touring ke Bali selama tiga hari. Sebanyak 232 rider dengan 92 pillion (istri yang ikut dibonceng naik motor) meramaikan touring moge Harley-Davidson ini.H.O.G. Indo Jakarta Chapter merupakan komunitas motor besar Harley-Davidson berskala international yang baru berdiri di Jakarta. Usia komunitas ini belum genap 1 tahun, tapi membernya sudah lebih dari 550 orang. Adapun acara ini merupakan touring ketiga yang dilakukan setelah Bandung dan Solo.*\n","\n","- Kategori Berita : *Otomotif*"],"metadata":{"id":"KCgSBe7SGKSf"}},{"cell_type":"markdown","source":["**Beautiful Soup (Python)**\n","\n","**Kelebihan:**\n","\n","*Mudah digunakan dan memiliki API yang intuitif.*\n","\n","*Cocok untuk proyek-proyek kecil hingga menengah.*\n","\n","*Fleksibel dalam parsing HTML dan XML.*\n","\n","**Kekurangan:**\n","\n","*Tidak sekuat Scrapy untuk proyek yang kompleks.*\n","\n","*Tidak memiliki fitur built-in untuk manajemen permintaan seperti Scrapy.*\n"],"metadata":{"id":"lX99fJdx25ji"}},{"cell_type":"markdown","source":["**Fungsi Crawling**\n","\n","\n","\n","1.   Mengindeks Halaman Web:\n","\n","\n","*   Crawling adalah langkah pertama dalam proses pengindeksan halaman web oleh mesin pencari. Web crawler akan mengunjungi halaman-halaman web, membaca kontennya, dan menyimpannya ke dalam indeks mesin pencari. Ini memungkinkan mesin pencari untuk menemukan dan menampilkan halaman-halaman tersebut dalam hasil pencarian.\n","\n","\n","\n","2.   Pengumpulan Data:\n","\n","*   Crawling memungkinkan pengumpulan data dari berbagai situs web untuk keperluan tertentu, seperti analisis bisnis, riset pasar, atau pengembangan model kecerdasan buatan. Dengan crawling, data dari berbagai sumber bisa dikumpulkan secara otomatis tanpa harus melakukannya secara manual.\n","\n","\n","\n","3. Pemantauan Perubahan Konten:\n","\n","*   Dengan crawling, perubahan atau pembaruan pada suatu situs web dapat dipantau secara berkala. Ini berguna untuk aplikasi yang memerlukan informasi terbaru, seperti agregator berita, alat pemantau harga, atau layanan notifikasi.\n","\n","\n","\n","4. SEO (Search Engine Optimization):\n","\n","*   Bagi pengelola situs web, memahami bagaimana proses crawling bekerja dapat membantu dalam optimasi mesin pencari (SEO). Dengan memastikan bahwa halaman-halaman web mereka mudah di-crawl dan diindeks, mereka bisa meningkatkan kemungkinan situs web mereka muncul di hasil pencarian mesin pencari.\n"],"metadata":{"id":"0hhGpPZnegJY"}},{"cell_type":"markdown","source":["**Teknologi yang Digunakan :**\n","\n","*   Library Pemrograman: Python dengan library seperti BeautifulSoup4, Scrapy, dan Requests adalah pilihan populer karena fleksibel dan memiliki banyak fitur.\n","\n","*   Python dan Scrapy : Scrapy adalah framework open-source di Python yang banyak digunakan untuk crawling data, termasuk berita online. Scrapy memudahkan proses fetching, parsing, dan menyimpan data.\n","\n","*   BeautifulSoup: Library Python ini digunakan untuk mengurai dokumen HTML dan XML, membantu mengekstrak data yang diinginkan dari halaman web.\n","\n","*   Selenium: Selenium digunakan untuk melakukan crawling pada halaman web yang memerlukan interaksi dinamis, seperti login atau scroll.\n","\n","*   API Berita: Beberapa situs berita menyediakan API yang memudahkan akses data mereka tanpa perlu crawling. Ini adalah cara yang lebih legal dan stabil untuk mendapatkan data.\n","\n","*   Perangkat Lunak Khusus: Ada juga perangkat lunak khusus yang dirancang untuk crawling data, seperti Octoparse dan ParseHub."],"metadata":{"id":"XwF-yl_ku2dQ"}},{"cell_type":"markdown","source":["**Beautiful Soup: Perpustakaan Python untuk Parsing HTML dan XML**\n","\n","**Beautiful Soup** *adalah sebuah perpustakaan Python yang sangat populer dan mudah digunakan untuk parsing dokumen HTML dan XML. Dengan menggunakan Beautiful Soup, kita dapat mengekstrak data dari halaman web dengan cara yang efisien dan elegan. Bayangkan BeautifulSoup sebagai sebuah parser yang dapat mengubah dokumen HTML atau XML yang berantakan menjadi struktur data yang mudah dipahami oleh Python.*\n","\n","**Mengapa Menggunakan BeautifulSoup?**\n","\n","*   Sederhana: BeautifulSoup memiliki API yang sangat intuitif dan mudah dipelajari, bahkan bagi pemula.\n","\n","*   Fleksibel: BeautifulSoup dapat digunakan untuk berbagai jenis parsing, mulai dari tugas sederhana hingga yang kompleks.\n","\n","*   Pythonic: BeautifulSoup terintegrasi dengan baik dengan ekosistem Python, sehingga Anda dapat dengan mudah menggabungkan BeautifulSoup dengan perpustakaan Python lainnya.\n","\n","*   Komunitas yang Besar: BeautifulSoup memiliki komunitas yang sangat aktif, sehingga Anda dapat dengan mudah menemukan dokumentasi, tutorial, dan bantuan jika Anda mengalami kesulitan.\n","\n"],"metadata":{"id":"uEf7xswQ-wj_"}},{"cell_type":"markdown","source":["**Kegunaan BeautifulSoup**\n","\n","**Web Scraping:** *Mengambil data dari halaman web untuk berbagai tujuan, seperti analisis sentimen, riset pasar, dan pengembangan aplikasi.*\n","\n","**Parsing Data:** *Mengubah data yang tidak terstruktur menjadi format yang terstruktur.*\n","\n","**Automasi:** *Mengotomatiskan tugas-tugas yang berulang, seperti mengunduh data dari banyak halaman web.*"],"metadata":{"id":"QmE78dNp_vty"}},{"cell_type":"markdown","source":["**Contoh Penggunaan Crawling Data :**\n","\n","**E-commerce:** *Untuk membandingkan harga produk dari berbagai toko online.*\n","\n","**Riset Pasar:** *Untuk mengumpulkan data tentang tren pasar, opini konsumen, atau perilaku kompetitor.*\n","\n","**Jurnalisme :** *Untuk mengumpulkan data dari berbagai sumber berita untuk membuat laporan yang komprehensif.*\n","\n","**Pengembangan Produk:** *Untuk mengumpulkan data yang dapat digunakan untuk melatih model machine learning dan mengembangkan produk baru.*\n","\n","**Akademik:** *Untuk mengumpulkan data untuk penelitian ilmiah.*"],"metadata":{"id":"pjMXIqnCznHf"}},{"cell_type":"markdown","source":["**Cara Crawling Data :**\n","\n","*pertama kita tentukan terlebih dahulu ingin mengambil data berita dari sumber mana, jika sudah menentukan data yang akan diambil dan di crawling, kemudian kita lakukan crawling data menggunakan code.*\n","\n","1. langkah pertama melakukan import Library yang akan mempermudah saat melakukan crawling data.\n","\n","- *import requests (digunakan untuk melakukan permintaan HTTP ke web server, seperti GET atau POST, dan mendapatkan tanggapan, termasuk HTML dari halaman web yang akan discrape.)*\n","\n","- *from bs4 import BeautifulSoup (digunakan untuk parsing dokumen HTML yang didapatkan dari permintaan HTTP, membuatnya lebih mudah untuk bergerak melalui struktur HTML, mencari elemen, dan mengubah data.)*\n","\n","- *import pandas as pd (library ini mengorganisir data dalam bentuk tabel, seperti dataframe, yang memudahkan analisis dan penyimpanan data kedalam format seperti CSV.)*\n","\n","- *import time (library  ini menambahkan jeda waktu, atau tidur, antara satu operasi dan operasi berikutnya, yang penting untuk proses crawling agar tidak terlalu banyak permintaan dalam waktu singkat.)*\n","\n","2. langkah kedua code mengambil data dari sebuah halaman web, memprosesnya, dan mengekstrak artikel-artikel yang relevan.\n","\n","3. langkah ketiga code melakukan pengecekan, dengan memeriksa satu per satu artikel yang ditemukan di halaman web. Jika sudah berhasil mengambil 10 artikel, prosesnya akan berhenti.\n","Untuk setiap artikel, kode akan mencari dan membuka link yang mengarah ke halaman detail artikel tersebut. Jika ada masalah seperti link rusak atau halaman tidak bisa dibuka, kode ini akan mencatat kesalahan tersebut dan langsung melanjutkan ke artikel berikutnya tanpa menghentikan keseluruhan proses pengambilan data.\n","\n","4. langkah keempat code mengambil judul, tanggal publikasi, dan isi dari setiap artikel yang ada di halaman web. Pertama, kode memproses halaman artikel dengan menggunakan BeautifulSoup untuk memudahkan pencarian elemen HTML yang berisi informasi tersebut. Jika elemen seperti judul, tanggal, atau isi ditemukan, data diambil dan disimpan dalam daftar; jika tidak ditemukan, elemen tersebut akan ditandai sebagai \"Tidak ditemukan\". Setiap judul artikel yang berhasil ditemukan akan dicetak di layar.\n","\n","5. langkah kelima code membuat dua daftar, atau list, yang digunakan dalam proses crawling data. Daftar pertama, base_urls, yang berisi URL halaman web yang akan diambil datanya,  halaman indeks DetikFood. Daftar kedua, categories, berisi kategori yang terkait dengan data yang ingin diambil, yaitu \"Makanan\". Keduanya akan digunakan bersama dalam proses crawling untuk menentukan halaman web mana yang harus diakses dan kategori mana yang relevan dengan pencarian.\n","\n","6. langkah keenam code membuat tiga daftar kosong, judul, tanggal, dan isi, yang akan digunakan untuk menyimpan data hasil crawling. Judul, tanggal, dan isi menyimpan judul dan konten utama artikel, dan daftar tanggal menyimpan tanggal publikasi setiap artikel. Ini mempersiapkan tempat untuk menyimpan data yang akan diambil dari halaman web di masa mendatang.\n","\n","7. langkah ketujuh membuat code Untuk setiap kombinasi URL dan kategori yang telah dibuat sebelumnya, kode ini melakukan proses iterasi, atau perulangan. Kode akan mengambil data dari beberapa halaman untuk setiap URL, mulai dari halaman 1 hingga 3. Jika jumlah artikel mencapai sepuluh, proses akan dihentikan. Setelah membuat URL baru yang sesuai untuk setiap halaman, fungsi get_data digunakan untuk mengambil data dari halaman tersebut. Untuk mencegah data diambil terlalu cepat, kode menunggu selama dua detik setelah mengambil data dari satu halaman sebelum melanjutkan ke halaman berikutnya.\n","\n","8. langkah terakhir membuat code untuk mengumpulkan data yang disimpan dalam bentuk daftar judul, tanggal, dan isi, lalu menyusunnya ke dalam bentuk tabel DataFrame menggunakan pustaka pandas. \"Judul\", \"tanggal\", dan \"isi\" adalah nama kolom dalam tabel DataFrame. Kode menyimpan tabel ke dalam file CSV dengan nama \"Crawl-berita.csv\" tanpa index. Setelah itu, Anda dapat membuka dan menganalisis file CSV ini menggunakan aplikasi spreadsheet atau perangkat lunak lain yang mendukung format CSV."],"metadata":{"id":"Xgid1T12Ffc5"}},{"cell_type":"markdown","source":["**Tujuan Crawling Berita Online :**\n","\n","**Mengumpulkan Informasi :** *Tujuan utama crawling berita adalah untuk mengumpulkan informasi terbaru dari berbagai sumber berita. Informasi ini bisa digunakan untuk membuat agregasi berita, analisis sentimen, atau membangun basis data untuk penelitian.*\n","\n","**Pemantauan Berita:** *Crawling dapat digunakan untuk memantau berita secara real-time, membantu perusahaan atau individu untuk tetap up-to-date dengan perkembangan terbaru.*\n","\n","**Pengindeksan untuk Mesin Pencari:** *Beberapa perusahaan melakukan crawling untuk mengindeks konten berita sehingga dapat ditampilkan dalam hasil pencarian.*\n","\n","**Membangun Agregator Berita:** *Data yang dikumpulkan oleh crawler dapat digunakan untuk membuat agregator berita, yaitu platform yang mengumpulkan berita dari berbagai sumber dan menyajikannya dalam satu tempat. Contohnya adalah Google News.*\n","\n","**Analisis Sentimen:** *Dengan mengumpulkan berita dalam jumlah besar, kita dapat menganalisis sentimen publik terhadap suatu topik tertentu. Misalnya, kita dapat mengetahui apakah opini publik terhadap suatu produk baru cenderung positif atau negatif.*\n","\n","**Riset Jurnalistik:** *Wartawan dapat menggunakan data yang dikumpulkan oleh crawler untuk melakukan investigasi atau membuat laporan yang lebih mendalam.*\n","\n","**Pengembangan AI:** *Data berita dapat digunakan untuk melatih model machine learning, misalnya untuk membuat sistem rekomendasi berita atau untuk menghasilkan berita secara otomatis.*\n"],"metadata":{"id":"5ni7fpJouiQo"}},{"cell_type":"markdown","source":["**Manfaat dan Penggunaan Data Hasil Crawling :**\n","\n","**Agregasi Berita :** *Data yang dikumpulkan dapat digunakan untuk membuat platform agregasi berita yang menyajikan berita dari berbagai sumber.*\n","\n","**Analisis Sentimen :** *Data berita dapat digunakan untuk analisis sentimen, membantu perusahaan memahami opini publik terhadap topik tertentu.*\n","\n","**Pemantauan Media :** Data dapat dimanfaatkan oleh agensi untuk memantau media dan menyusun laporan tentang tren berita.\n","\n","**Penelitian :** *Peneliti dapat menggunakan data hasil crawling untuk studi terkait jurnalisme, media, atau fenomena sosial lainnya.*"],"metadata":{"id":"OlppCIkrvGHB"}},{"cell_type":"markdown","source":["\n","# Code Program Proses **Crawling Berita Online :**"],"metadata":{"id":"hjuJ1soi9nnW"}},{"cell_type":"markdown","source":["Dalam proses crawling ini saya menggunakan beberapa library dan diantara library yang penting di import adalah *BeautifulSoup* yang berfungsi sebagai library crawler"],"metadata":{"id":"0QK7cgSn5tzj"}},{"cell_type":"code","source":["import requests\n","from bs4 import BeautifulSoup\n","import pandas as pd\n","import time"],"metadata":{"id":"EYQJAGZF3700"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Membuat fungsi filter konten\n","Berfungsi untuk Mem-filter dari elemen-elemen HTML pada berita yang tidak diinginkan , Contoh kasus seperti iklan, daftar isi, gambar , link sisipan, dll"],"metadata":{"id":"Vhr74Iid5xLi"}},{"cell_type":"code","source":["\n","# Fungsi untuk membersihkan konten dari elemen-elemen yang tidak diinginkan\n","def clean_content(content_element):\n","    if content_element:\n","        # Hapus elemen yang berisi daftar isi\n","        for daftar_isi in [\"collapsible\"]:\n","            unwanted = content_element.find(\"div\", id=daftar_isi)\n","            if unwanted:\n","                unwanted.decompose()\n","\n","        # Hapus elemen yang berisi tag\n","        for tag_class in [\"aevp\", \"detail__body-tag mgt-16\"]:\n","            unwanted = content_element.find_all(\"div\", class_=tag_class)\n","            for el in unwanted:\n","                el.decompose()\n","\n","        # Hapus elemen yang berisi link sisipan\n","        link_sisip = content_element.find_all(\"table\", class_=\"linksisip\")\n","        for table in link_sisip:\n","            table.decompose()\n","\n","        # Hapus elemen paragraf dan span dengan class 'para_caption'\n","        unwanted_paragraphs = content_element.find_all([\"p\", \"span\"], class_=\"para_caption\")\n","        for para in unwanted_paragraphs:\n","            para.decompose()\n","\n","        # Kembalikan teks yang tersisa\n","        return content_element.get_text(separator=' ', strip=True).strip()\n","\n","    return \"Content Not Found\"\n"],"metadata":{"id":"9IsJH1rK4UYI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Membuat fungsi untuk melakukan crawling data pada situs web Detik.com.\n","Fungsi ini mengambil data berupa judul berita, tanggal publikasi, isi berita dan kategori berita yang terdapat di halaman tersebut.\n"],"metadata":{"id":"WKwwqJq15zaJ"}},{"cell_type":"code","source":["# Fungsi untuk mengambil data dari halaman web Detik.com\n","def get_data(url, kategori, min_articles_per_category):\n","    try:\n","        response = requests.get(url)\n","        response.raise_for_status()\n","    except requests.exceptions.RequestException as e:\n","        print(f\"Request failed: {e}\")\n","        return\n","\n","    soup = BeautifulSoup(response.content, \"html.parser\")\n","    articles = soup.find_all(\"article\", class_=\"list-content__item\")\n","\n","    for article in articles:\n","        if len([k for k in kategori_list if k == kategori]) >= min_articles_per_category:\n","            return  # Menghentikan proses jika jumlah artikel sudah mencapai minimum yang diinginkan\n","\n","        try:\n","            link = article.find(\"a\")[\"href\"]\n","            article_response = requests.get(link)\n","            article_response.raise_for_status()\n","        except (requests.exceptions.RequestException, TypeError) as e:\n","            print(f\"Request for article failed: {e}\")\n","            continue\n","\n","        article_soup = BeautifulSoup(article_response.content, \"html.parser\")\n","        title_element = article_soup.find(\"h1\", class_=\"detail__title\")\n","        title = title_element.text.strip() if title_element else \"Title Not Found\"\n","        date_element = article_soup.find(\"div\", class_=\"detail__date\")\n","        date = date_element.text.strip() if date_element else \"Date Not Found\"\n","        content_element = article_soup.find(\"div\", class_=\"detail__body-text\")\n","        content = content_element.text.strip() if content_element else \"Content Not Found\"\n","\n","        # Bersihkan konten menggunakan fungsi clean_content\n","        content = clean_content(content_element)\n","\n","        judul.append(title)\n","        tanggal.append(date)\n","        isi.append(content)\n","        kategori_list.append(kategori)\n","\n","        if len(judul) <= 10:\n","            print(title)\n","        time.sleep(1)\n","\n","# Membuat list url dan kategori yang akan di-crawl\n","base_urls = [\n","    \"https://oto.detik.com/indeks\",\n","    \"https://finance.detik.com/indeks\",\n","]\n","categories = [\n","    \"Otomotif\",\n","    \"Keuangan\",\n","]\n","\n","# Inisialisasi list untuk menyimpan data\n","judul = []\n","tanggal = []\n","isi = []\n","kategori_list = []\n","\n","# Batas minimal artikel per kategori\n","min_articles_per_category = 50\n","\n","# Melakukan iterasi untuk setiap url dan kategori\n","for base_url, category in zip(base_urls, categories):\n","    page = 1\n","    while len([k for k in kategori_list if k == category]) < min_articles_per_category:\n","        url = f\"{base_url}/{page}\"\n","        get_data(url, category, min_articles_per_category)\n","        time.sleep(2)\n","        page += 1\n","\n","# Membuat dataframe dari list data\n","df = pd.DataFrame({\"judul\": judul, \"tanggal\": tanggal, \"isi\": isi, \"kategori\": kategori_list})\n","\n","# Menyimpan dataframe ke file csv\n","df.to_csv(\"Crawl-berita-Otomotif&Finance.csv\", index=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oByQn8w6jIpB","executionInfo":{"status":"ok","timestamp":1726728139973,"user_tz":-420,"elapsed":321346,"user":{"displayName":"","userId":""}},"outputId":"ad020c94-e437-4632-eef4-f35822ac885b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Nunggak 8 Bulan, Segini Pajak Ford Mustang Milik Bos Narkoba HS\n","Bos Ford Kaget usai Jajal Mobil China: Mereka Lebih Maju!\n","Tarif Tol Dalam Kota Naik Jadi Segini, Berlaku 22 September\n","Pak RT Aleix Espargaro Tak Sabar Balapan Terakhir di Sirkuit Mandalika\n","Angkot Listrik Bakal Diuji Coba di Jakarta\n","Muncul Kode Diduga HR-V Hybrid di Indonesia, Segini Bocoran Harganya\n","Tiket MotoGP Mandalika Diobral Rp 50 Ribu, Khusus untuk Pelajar\n","Gara-gara Ini Orang Indonesia Masih Banyak yang Kepincut Kijang Innova\n","11 Bus Baru PO Harapan Jaya Lahir dari Garasi Laksana\n","Kendaraan Sudah Dijual, Jangan Lupa STNK-nya Diblokir Biar Nggak Begini!\n"]}]},{"cell_type":"code","source":["df=pd.read_csv(\"Crawl-berita-Otomotif&Finance.csv\")\n","df.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"KKywMWqhiSoc","executionInfo":{"status":"ok","timestamp":1726728139973,"user_tz":-420,"elapsed":23,"user":{"displayName":"","userId":""}},"outputId":"830806ac-3167-44d4-8bcc-7105166c4efa"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                               judul  \\\n","0  Nunggak 8 Bulan, Segini Pajak Ford Mustang Mil...   \n","1  Bos Ford Kaget usai Jajal Mobil China: Mereka ...   \n","2  Tarif Tol Dalam Kota Naik Jadi Segini, Berlaku...   \n","3  Pak RT Aleix Espargaro Tak Sabar Balapan Terak...   \n","4         Angkot Listrik Bakal Diuji Coba di Jakarta   \n","5  Muncul Kode Diduga HR-V Hybrid di Indonesia, S...   \n","6  Tiket MotoGP Mandalika Diobral Rp 50 Ribu, Khu...   \n","7  Gara-gara Ini Orang Indonesia Masih Banyak yan...   \n","8  11 Bus Baru PO Harapan Jaya Lahir dari Garasi ...   \n","9  Kendaraan Sudah Dijual, Jangan Lupa STNK-nya D...   \n","\n","                        tanggal  \\\n","0  Kamis, 19 Sep 2024 13:05 WIB   \n","1  Kamis, 19 Sep 2024 12:33 WIB   \n","2  Kamis, 19 Sep 2024 12:08 WIB   \n","3  Kamis, 19 Sep 2024 11:40 WIB   \n","4  Kamis, 19 Sep 2024 11:18 WIB   \n","5  Kamis, 19 Sep 2024 10:37 WIB   \n","6  Kamis, 19 Sep 2024 10:07 WIB   \n","7  Kamis, 19 Sep 2024 09:38 WIB   \n","8  Kamis, 19 Sep 2024 09:14 WIB   \n","9  Kamis, 19 Sep 2024 08:53 WIB   \n","\n","                                                 isi  kategori  \n","0  Jakarta - Bareskrim Polri menyita aset senilai...  Otomotif  \n","1  Jakarta - Chief Executive Officer (CEO) Ford, ...  Otomotif  \n","2  Jakarta - Jasa Marga mengumumkan kenaikan tari...  Otomotif  \n","3  Jakarta - Pebalap Aprilia asal Spanyol, Aleix ...  Otomotif  \n","4  Jakarta - PT Transportasi Jakarta (TransJakart...  Otomotif  \n","5  Jakarta - Honda tampaknya sedang menyiapkan pr...  Otomotif  \n","6  Jakarta - Meski akan digelar pekan depan, namu...  Otomotif  \n","7  Jakarta - Pesona Kijang Innova belum luntur. M...  Otomotif  \n","8  Jakarta - PO Harapan Jaya kembali merilis arma...  Otomotif  \n","9  Jakarta - STNK kendaraan yang sudah dijual waj...  Otomotif  "],"text/html":["\n","  <div id=\"df-bc7bcdc9-e96b-45cb-a547-f5e88783f095\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>judul</th>\n","      <th>tanggal</th>\n","      <th>isi</th>\n","      <th>kategori</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Nunggak 8 Bulan, Segini Pajak Ford Mustang Mil...</td>\n","      <td>Kamis, 19 Sep 2024 13:05 WIB</td>\n","      <td>Jakarta - Bareskrim Polri menyita aset senilai...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Bos Ford Kaget usai Jajal Mobil China: Mereka ...</td>\n","      <td>Kamis, 19 Sep 2024 12:33 WIB</td>\n","      <td>Jakarta - Chief Executive Officer (CEO) Ford, ...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Tarif Tol Dalam Kota Naik Jadi Segini, Berlaku...</td>\n","      <td>Kamis, 19 Sep 2024 12:08 WIB</td>\n","      <td>Jakarta - Jasa Marga mengumumkan kenaikan tari...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Pak RT Aleix Espargaro Tak Sabar Balapan Terak...</td>\n","      <td>Kamis, 19 Sep 2024 11:40 WIB</td>\n","      <td>Jakarta - Pebalap Aprilia asal Spanyol, Aleix ...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Angkot Listrik Bakal Diuji Coba di Jakarta</td>\n","      <td>Kamis, 19 Sep 2024 11:18 WIB</td>\n","      <td>Jakarta - PT Transportasi Jakarta (TransJakart...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>Muncul Kode Diduga HR-V Hybrid di Indonesia, S...</td>\n","      <td>Kamis, 19 Sep 2024 10:37 WIB</td>\n","      <td>Jakarta - Honda tampaknya sedang menyiapkan pr...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Tiket MotoGP Mandalika Diobral Rp 50 Ribu, Khu...</td>\n","      <td>Kamis, 19 Sep 2024 10:07 WIB</td>\n","      <td>Jakarta - Meski akan digelar pekan depan, namu...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Gara-gara Ini Orang Indonesia Masih Banyak yan...</td>\n","      <td>Kamis, 19 Sep 2024 09:38 WIB</td>\n","      <td>Jakarta - Pesona Kijang Innova belum luntur. M...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>11 Bus Baru PO Harapan Jaya Lahir dari Garasi ...</td>\n","      <td>Kamis, 19 Sep 2024 09:14 WIB</td>\n","      <td>Jakarta - PO Harapan Jaya kembali merilis arma...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Kendaraan Sudah Dijual, Jangan Lupa STNK-nya D...</td>\n","      <td>Kamis, 19 Sep 2024 08:53 WIB</td>\n","      <td>Jakarta - STNK kendaraan yang sudah dijual waj...</td>\n","      <td>Otomotif</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc7bcdc9-e96b-45cb-a547-f5e88783f095')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-bc7bcdc9-e96b-45cb-a547-f5e88783f095 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-bc7bcdc9-e96b-45cb-a547-f5e88783f095');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-cf3dfe9f-9b7c-407c-9d65-eb40cbad0737\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cf3dfe9f-9b7c-407c-9d65-eb40cbad0737')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-cf3dfe9f-9b7c-407c-9d65-eb40cbad0737 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","\n","    </div>\n","  </div>\n"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"dataframe","variable_name":"df","summary":"{\n  \"name\": \"df\",\n  \"rows\": 100,\n  \"fields\": [\n    {\n      \"column\": \"judul\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"The Fed Turunkan Suku Bunga Jadi Angin Segar Termasuk ke RI, Ini Buktinya\",\n          \"MG Siap Bawa Mobil SUV Baru ke Indonesia, Ini Bocorannya\",\n          \"Ini Maskapai Asing Pertama Pakai Avtur Campur Minyak Jelantah Pertamina\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"tanggal\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 97,\n        \"samples\": [\n          \"Kamis, 19 Sep 2024 11:47 WIB\",\n          \"Rabu, 18 Sep 2024 07:32 WIB\",\n          \"Rabu, 18 Sep 2024 21:29 WIB\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"isi\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 99,\n        \"samples\": [\n          \"Jakarta - Bank Sentral Amerika Serikat (AS), The Federal Reserve (The Fed) menurunkan suku bunga. Keputusan The Fed akan memberikan dampak yang besar kepada perekonomian dunia, khususnya negara berkembang. Pada pertemuan September, Komite Pasar Terbuka Federal The Fed (Federal Open Market Committee/FOMC) memutuskan untuk memangkas suku bunga acuan. Gubernur The Fed, Jerome Powell memangkas suku bunga menjadi 4,75-5% atau 50 basis poin (bps). Keputusan The Fed untuk mengakhiri pengetatan ekonomi terbarunya karena melonjaknya inflasi, diperkirakan terasa di seluruh dunia. Per Agustus inflasi tahunan mencapai 5,9% secara global menurut Dana Moneter Internasional (International Monetary Fund/IMF), dilaporkan juga inflasi rata-rata negara maju seperti AS sudah mulai rendah mendekati 2,6%. Ketika The Fed menaikkan dan menahan bunga acuan, maka bank sentral negara lain juga ikut melakukan hal serupa. Kemudian, setelah The Fed menurunkan suku bunga, bank sentral berbagai negara pun ikut menurunkannya. Bank Sentral Eropa bahkan telah memangkas suku bunga acuan lebih dulu dua kali pada tahun ini menjelang The Fed menurunkan suku bunga. Bank Indonesia (BI) juga kemarin sudah menurunkan suku bunga. Direktur Pusat Psaros untuk Pasar Keuangan dan Kebijakan Georgetown University, Reena Aggarwal mengamini dampak kebijakan The Fed memang berdampak besar ke perekonomian dunia. \\\"Langkah Dewan Federal Reserve tidak hanya berdampak di AS. Tindakan tersebut memiliki implikasi, efek limpahan di bagian lain dunia juga,\\\" kata Aggarwal dikutip dari CNN , Kamis (19/9/2024). Keputusan The Fed juga dapat mempengaruhi pasar valuta asing (valas) mengingat pengaruhnya terhadap nilai tukar dolar AS yang selama ini menjadi mata uang cadangan global. Hal ini dapat berimbas besar pada utang dan piutang negara-negara berkembang yang menggunakan dolar AS. Bila bunga pinjaman turun, otomatis biaya pinjaman akan menjadi lebih murah. \\\"Pasar negara berkembang terdampak karena banyak pinjaman mereka dalam dolar AS. Jadi mereka harus membayar bunga dan pokok dalam dolar, dan jika suku bunga berubah di AS, semua biaya pinjaman berubah,\\\" sebut Aggarwal. Maka dari itu, beberapa negara lain telah berupaya meningkatkan profil mata uang mereka demi terbebas dari dampak yang terjadi pada kebijakan The Fed. Yang paling menonjol adalah Bank Sentral China (People Bank of China/PBOC) yang telah membentuk sistem moneter internasional sendiri menggunakan yuan atau renminbi. Sejauh ini dampak penurunan bunga The Fed di Indonesia cukup memberikan angin segar kepada pasar keuangan. Nilai tukar rupiah menguat tipis 0,35% terhadap dolar AS di level Rp 15.275, sementara itu Indeks Harga Saham Gabungan (IHSG) juga menguat 0,75% di level 7.887,76 pagi tadi. (hal/ara)\",\n          \"Jakarta - MG Motor Indonesia terus memperluas portofolio produknya di Indonesia. Merek Inggris yang kini dimiliki oleh SAIC Motor China itu bakal memperkenalkan beberapa produk baru tahun depan, salah satunya adalah mobil jenis SUV. \\\"Kami pikir kami akan memiliki produk-produk baru (untuk pasar Indonesia ke depannya). Mungkin banyak orang berpikir mudah untuk membawa produk-produk mobil baru untuk pasar yang berbeda seperti Indonesia. Tapi kenyataannya tidak. Karena kami adalah perusahaan (peringkat) Fortune 500, kami memiliki banyak departemen, dan di setiap departemennya harus lakukan komunikasi, termasuk soal desain, kualitas, harga, taxation , termasuk juga situasi politik dan ekonomi lokal,\\\" bilang Chief Executive Officer MG Motor Indonesia He Guowei kepada wartawan di Jakarta, Selasa (17/9/2024). Ditambahkan ATL Manager & Creative Strategist MG Motor Indonesia Muhamad Irvan Mustafa, MG Motor Indonesia akan meluncurkan beberapa produk baru pada tahun 2025. \\\"Pasti akan nambah (produk baru) kita nggak mau sekedar ada 7 produk,\\\" ungkap Irvan dalam kesempatan yang sama. Pada pertemuan dengan awak media tersebut, MG Motor Indonesia turut menampilkan teaser mobil baru yang akan diperkenalkannya tahun depan. Dalam tayangan video itu, calon mobil anyar MG mengusung desain SUV. Sayang detailnya belum kelihatan lantaran mobil berselimut stiker kamuflase. \\\"Yang tadi (kita perlihatkan) itu SUV. Ini tahun depan (akan kita perkenalkan ke masyarakat Indonesia),\\\" tambah Irvan sambil menyebut kemungkinan mobil tersebut bisa jadi memiliki mesin listrik maupun mesin konvensional. Lanjut Irvan mengatakan, MG akan memperkenalkan antara 2 hingga 3 produk baru untuk pasar Indonesia tahun depan. Saat ini MG Motor Indonesia memiliki beberapa model yang sudah dipasarkan, antara lain MG 4 EV, New ZS EV, Cyberster, MG VS, MG ZS, MG 5 GT, dan New MG HS. (lua/din)\",\n          \"Jakarta - Virgin Australia Airlines menjadi maskapai internasional pertama yang memakai Sustainable Aviation Fuel (SAF) dari Aviation Fuel Terminal (AFT) Ngurah Rai. Hal ini ditandai dengan seremoni First International Uplift pada perhelatan Bali International Airshow di Bandara Internasional I Gusti Ngurah Rai. Penggunaan SAF pada Virgin Australia Airline merupakan langkah PT Pertamina Patra Niaga memperluas distribusi SAF ke jaringan global. SAF sendiri merupakan bioavtur yang berasal used cooking oil (UCO) atau minyak jelantah. \\\"Momen penyaluran pertama SAF di Bandara Ngurah Rai ini menandai bahwa Indonesia dapat beradaptasi dengan tuntutan bauran energi di industri penerbangan internasional, di mana saat ini SAF menjadi solusi jangka menengah bagi penerbangan untuk mengurangi jejak karbon, tanpa memerlukan perubahan pada pesawat, infrastruktur bandara, atau rantai pasokan bahan bakar jet,\\\" ungkap Direktur Pemasaran Pusat dan Niaga Pertamina Patra Niaga, Maya Kusmaya dalam keterangan tertulis, Rabu (18/9/2024). Maya menambahkan, SAF yang disalurkan sudah mengacu framework sertifikasi International Sustainability and Carbon Certification (ISCC) untuk Carbon Offsetting and Reduction Scheme for International Aviation (CORSIA) dan Renewable Energy Directive-European Union (RED-EU). Selain itu, SAF telah memenuhi standar internasional yang diatur oleh American Society of Testing and Materials (ASTM) dan terjamin aman karena sudah termasuk sebagai Corsia Eligible Fuel (CEF) yang dapat diklaim kepada International Civil Aviation Organization (ICAO). \\\"Langkah baru menuju penerbangan berkelanjutan ini mampu mengurangi emisi karbon dari bahan bakar fosil, karena SAF Pertamina merupakan perpaduan dari 38,43% synthetic kerosene yang diproduksi dari minyak jelantah atau Used Cooking Oil (UCO) dan 61,57% avtur yang berasal dari fosil,\\\" tambahnya. General Manager Sustainability Virgin Australia, Fiona Walmsley, pada kesempatan yang sama mengatakan, kerja sama ini merupakan langkah awal antara Indonesia dan Australia dalam upaya mewujudkan target Net Zero Emission di kedua negara. \\\"Dengan bergandengan tangan, Indonesia dan Australia berkomitmen untuk mengurangi jejak karbon dan mengimplementasikan solusi ramah lingkungan yang inovatif. Kolaborasi ini menunjukkan tekad untuk membangun masa depan sektor aviasi yang lebih berkelanjutan dan bersih,\\\" kata Fiona. Sebanyak kurang lebih 160 kiloliter SAF disalurkan kepada Pesawat Boeing 737 milik Virgin Australia pada gelaran Bali International Airshow untuk dua hari penerbangan Virgin Australia di Ngurah Rai, yaitu pada 18 hingga 19 September 2024. Sebagai informasi, Virgin Australia turut melayani rute penerbangan dari Denpasar ke Brisbane, Melbourne, Sydney, dan Gold Coast. SAF yang disalurkan di Aviation Fuel Terminal Ngurah Rai dikelola menggunakan metode chain of custody tipe mass balance. Dalam metode ini, produk avtur konvensional berbahan bakar fosil dicampurkan dengan bahan bakar terbarukan (SAF) dalam tangki yang sama karena keduanya memiliki spesifikasi teknis yang serupa. Meskipun dicampur, pencatatan dan pembukuan avtur dan SAF dilakukan secara terpisah. Penyaluran SAF ke pasar global menjadi komitmen nyata Pertamina Patra Niaga yang secara agresif mendorong transisi energi di sektor aviasi dan mendukung target Net Zero Emission Indonesia tahun 2060. SAF yang diproduksi dari limbah, diolah di kilang bersamaan dengan bahan bakar fosil untuk menghasilkan bahan bakar sintetis rendah karbon, mengurangi emisi karbon hingga 84% dibandingkan bahan bakar jet konvensional, serta telah disertifikasi ISCC CORSIA dan ISCC RED-EU. (acd/rrd)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kategori\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Keuangan\",\n          \"Otomotif\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"}},"metadata":{},"execution_count":12}]},{"cell_type":"markdown","source":["# PENJELASAN CODE PROGRAM **CRAWLING DATA BERITA ONLINE :**"],"metadata":{"id":"HEKndHZbwI7O"}}]}